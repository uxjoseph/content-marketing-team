#!/usr/bin/env python3
"""
ìŒì„± ì¸ì‹ ë° ìë§‰ ìƒì„± ìŠ¤í¬ë¦½íŠ¸
OpenAI Whisperë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ìƒì—ì„œ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
"""

import argparse
import json
import os
import subprocess
import sys
from pathlib import Path
from typing import Dict, List, Optional

try:
    import whisper
except ImportError:
    print("Error: whisperê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    print("ì„¤ì¹˜: pip install openai-whisper")
    sys.exit(1)


def extract_audio(video_path: str, audio_path: str) -> str:
    """
    ì˜ìƒì—ì„œ ì˜¤ë””ì˜¤ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.

    Args:
        video_path: ì…ë ¥ ì˜ìƒ íŒŒì¼ ê²½ë¡œ
        audio_path: ì¶œë ¥ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ

    Returns:
        ì¶”ì¶œëœ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
    """
    print(f"ğŸµ ì˜¤ë””ì˜¤ ì¶”ì¶œ ì¤‘: {video_path}")

    # ffmpeg ëª…ë ¹ì–´
    cmd = [
        "ffmpeg",
        "-i", video_path,
        "-vn",  # ë¹„ë””ì˜¤ ì œì™¸
        "-acodec", "pcm_s16le",  # PCM 16-bit
        "-ar", "16000",  # 16kHz ìƒ˜í”Œë ˆì´íŠ¸ (Whisper ê¶Œì¥)
        "-ac", "1",  # ëª¨ë…¸
        "-y",  # ë®ì–´ì“°ê¸°
        audio_path,
    ]

    try:
        subprocess.run(cmd, check=True, capture_output=True)
        print(f"   âœ… ì˜¤ë””ì˜¤ ì¶”ì¶œ ì™„ë£Œ: {audio_path}")
        return audio_path
    except subprocess.CalledProcessError as e:
        print(f"   âŒ ì˜¤ë””ì˜¤ ì¶”ì¶œ ì‹¤íŒ¨: {e.stderr.decode()}")
        sys.exit(1)
    except FileNotFoundError:
        print("   âŒ ffmpegê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("   ì„¤ì¹˜: brew install ffmpeg (macOS) ë˜ëŠ” apt-get install ffmpeg (Ubuntu)")
        sys.exit(1)


def transcribe_audio(
    audio_path: str,
    model_name: str = "base",
    language: str = "ko",
) -> Dict:
    """
    ì˜¤ë””ì˜¤ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

    Args:
        audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        model_name: Whisper ëª¨ë¸ ì´ë¦„ (tiny, base, small, medium, large)
        language: ì–¸ì–´ ì½”ë“œ

    Returns:
        ë³€í™˜ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    print(f"ğŸ¤ ìŒì„± ì¸ì‹ ì¤‘... (ëª¨ë¸: {model_name})")
    print("   â³ ëª¨ë¸ ë¡œë”© ì¤‘ (ì²˜ìŒ ì‹¤í–‰ ì‹œ ë‹¤ìš´ë¡œë“œë¨)...")

    # ëª¨ë¸ ë¡œë“œ
    model = whisper.load_model(model_name)
    print(f"   âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

    # ìŒì„± ì¸ì‹ ì‹¤í–‰
    print("   ğŸ”Š ìŒì„± ì¸ì‹ ì§„í–‰ ì¤‘...")
    result = model.transcribe(
        audio_path,
        language=language,
        verbose=False,
        word_timestamps=True,  # ë‹¨ì–´ë³„ íƒ€ì„ìŠ¤íƒ¬í”„
    )

    print(f"   âœ… ìŒì„± ì¸ì‹ ì™„ë£Œ")

    return result


def format_transcript(result: Dict) -> Dict:
    """
    Whisper ê²°ê³¼ë¥¼ ì •í˜•í™”ëœ í¬ë§·ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

    Args:
        result: Whisper ë³€í™˜ ê²°ê³¼

    Returns:
        ì •í˜•í™”ëœ íŠ¸ëœìŠ¤í¬ë¦½íŠ¸
    """
    segments = []

    for segment in result.get("segments", []):
        formatted_segment = {
            "id": segment.get("id"),
            "start": round(segment.get("start", 0), 2),
            "end": round(segment.get("end", 0), 2),
            "text": segment.get("text", "").strip(),
            "words": [],
        }

        # ë‹¨ì–´ë³„ íƒ€ì„ìŠ¤íƒ¬í”„ (ìˆìœ¼ë©´)
        if "words" in segment:
            for word in segment["words"]:
                formatted_segment["words"].append({
                    "word": word.get("word", "").strip(),
                    "start": round(word.get("start", 0), 2),
                    "end": round(word.get("end", 0), 2),
                })

        segments.append(formatted_segment)

    transcript = {
        "language": result.get("language", "unknown"),
        "duration": round(segments[-1]["end"], 2) if segments else 0,
        "text": result.get("text", "").strip(),
        "segments": segments,
    }

    return transcript


def save_transcript(transcript: Dict, output_path: str) -> str:
    """
    íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.

    Args:
        transcript: íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ë”•ì…”ë„ˆë¦¬
        output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ

    Returns:
        ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
    """
    output_file = Path(output_path)
    output_file.parent.mkdir(parents=True, exist_ok=True)

    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(transcript, f, ensure_ascii=False, indent=2)

    print(f"ğŸ’¾ íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ì €ì¥ ì™„ë£Œ: {output_path}")
    return str(output_file)


def generate_srt(transcript: Dict, output_path: str) -> str:
    """
    SRT ìë§‰ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        transcript: íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ë”•ì…”ë„ˆë¦¬
        output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ (.srt)

    Returns:
        ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
    """
    def format_time(seconds: float) -> str:
        """ì´ˆë¥¼ SRT ì‹œê°„ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        millis = int((seconds - int(seconds)) * 1000)
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"

    srt_content = []
    for i, segment in enumerate(transcript["segments"], 1):
        start_time = format_time(segment["start"])
        end_time = format_time(segment["end"])
        text = segment["text"]

        srt_content.append(f"{i}")
        srt_content.append(f"{start_time} --> {end_time}")
        srt_content.append(text)
        srt_content.append("")  # ë¹ˆ ì¤„

    output_file = Path(output_path)
    with open(output_file, "w", encoding="utf-8") as f:
        f.write("\n".join(srt_content))

    print(f"ğŸ“ SRT ìë§‰ ì €ì¥ ì™„ë£Œ: {output_path}")
    return str(output_file)


def main():
    parser = argparse.ArgumentParser(
        description="ì˜ìƒ ìŒì„± ì¸ì‹ ë° ìë§‰ ìƒì„±",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì‹œ:
  python transcribe.py --input video.mp4 --output transcript.json
  python transcribe.py -i video.mp4 -o transcript.json --model medium --language ko

ëª¨ë¸ ì„ íƒ:
  tiny   - ê°€ì¥ ë¹ ë¦„, ì •í™•ë„ ë‚®ìŒ (~1GB VRAM)
  base   - ë¹ ë¦„, ì ë‹¹í•œ ì •í™•ë„ (~1GB VRAM) [ê¸°ë³¸ê°’]
  small  - ê· í˜•ì¡íŒ ì†ë„/ì •í™•ë„ (~2GB VRAM)
  medium - ë†’ì€ ì •í™•ë„ (~5GB VRAM)
  large  - ìµœê³  ì •í™•ë„, ê°€ì¥ ëŠë¦¼ (~10GB VRAM)
        """,
    )

    parser.add_argument(
        "--input", "-i", required=True, help="ì…ë ¥ ì˜ìƒ íŒŒì¼ ê²½ë¡œ"
    )
    parser.add_argument(
        "--output", "-o", required=True, help="ì¶œë ¥ JSON íŒŒì¼ ê²½ë¡œ"
    )
    parser.add_argument(
        "--model", "-m", default="base",
        choices=["tiny", "base", "small", "medium", "large"],
        help="Whisper ëª¨ë¸ (ê¸°ë³¸ê°’: base)"
    )
    parser.add_argument(
        "--language", "-l", default="ko", help="ì–¸ì–´ ì½”ë“œ (ê¸°ë³¸ê°’: ko)"
    )
    parser.add_argument(
        "--srt", "-s", action="store_true", help="SRT ìë§‰ íŒŒì¼ë„ ìƒì„±"
    )

    args = parser.parse_args()

    # ì…ë ¥ íŒŒì¼ í™•ì¸
    if not os.path.exists(args.input):
        print(f"âŒ ì…ë ¥ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.input}")
        sys.exit(1)

    print("=" * 50)
    print("ğŸ¬ ì˜ìƒ ìŒì„± ì¸ì‹ ì‹œì‘")
    print("=" * 50)

    # 1. ì˜¤ë””ì˜¤ ì¶”ì¶œ
    audio_path = args.input.rsplit(".", 1)[0] + "_audio.wav"
    extract_audio(args.input, audio_path)

    # 2. ìŒì„± ì¸ì‹
    result = transcribe_audio(audio_path, args.model, args.language)

    # 3. ê²°ê³¼ í¬ë§·íŒ…
    transcript = format_transcript(result)

    # 4. JSON ì €ì¥
    save_transcript(transcript, args.output)

    # 5. SRT ì €ì¥ (ì˜µì…˜)
    if args.srt:
        srt_path = args.output.rsplit(".", 1)[0] + ".srt"
        generate_srt(transcript, srt_path)

    # 6. ì„ì‹œ ì˜¤ë””ì˜¤ íŒŒì¼ ì •ë¦¬
    if os.path.exists(audio_path):
        os.remove(audio_path)
        print(f"ğŸ§¹ ì„ì‹œ íŒŒì¼ ì •ë¦¬: {audio_path}")

    print("=" * 50)
    print("âœ… ìŒì„± ì¸ì‹ ì™„ë£Œ!")
    print(f"   ì „ì²´ ê¸¸ì´: {transcript['duration']}ì´ˆ")
    print(f"   ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜: {len(transcript['segments'])}ê°œ")
    print("=" * 50)

    return args.output


if __name__ == "__main__":
    main()
